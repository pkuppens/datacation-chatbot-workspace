{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent to EDA assistent\n",
    "\n",
    "In this second part, we will expand on the agent and add abilities (tools) to inspect a certain dataset.\n",
    "\n",
    "This notebook will guide you through the steps, but some parts are left as exercises for you to complete.\n",
    "\n",
    "> REMEMBER: The notebook is just there to experiment; the end result needs to be present in `chat_app.py` to be able to interactively chat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "# We need to add some necessary dependencies\n",
    "\n",
    "uv add datasets pandas sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The Titanic dataset is a wellknown standard dataset denoting the passengers of the Titanic. It is primarily used for causality regarding the survival rate.\n",
    "\n",
    "To load the Titanic dataset, we use the `load_dataset` function from the `datasets` library. This function allows us to easily access and convert the dataset into a pandas DataFrame for further analysis. The Titanic dataset is available at [Hugging Face Datasets](https://huggingface.co/datasets/mstz/titanic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5cb4db025d40f2a4b955408588e149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Repos\\pkuppens\\datacation-chatbot-workspace\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\piete\\.cache\\huggingface\\hub\\datasets--mstz--titanic. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfedf5f7dda4faaa307c047654e8e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "titanic.py:   0%|          | 0.00/2.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e666e753fc9c4886a22db7fbe63376ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0000.parquet:   0%|          | 0.00/16.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9426c22f5f4e4a1ba4e964dc3f92d86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/891 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mstz/titanic\")[\"train\"]\n",
    "titanic_df: pd.DataFrame = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain's SQL Database Integration\n",
    "\n",
    "In this section, we will explore how to leverage LangChain's SQL Database integration to interact with and analyze structured data. LangChain provides a seamless way to connect to SQL databases, execute queries, and retrieve results for further processing.\n",
    "\n",
    "The integration allows us to:\n",
    "\n",
    "- Connect to various SQL databases using supported drivers.\n",
    "- Perform complex queries to extract insights from the data.\n",
    "- Combine SQL capabilities with LangChain's tools for advanced data manipulation and analysis.\n",
    "\n",
    "For more details, refer to the [LangChain SQL Database Integration Documentation](https://python.langchain.com/docs/integrations/tools/sql_database/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an in-memory SQLite database engine\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "\n",
    "# to_sql() parameters:\n",
    "# - 'titanic': Name of the SQL table to create\n",
    "# - engine: SQLAlchemy engine to use for database connection\n",
    "# - if_exists='replace': If table exists, drop and recreate it (other options: 'fail', 'append')\n",
    "# - index=False: Don't include the DataFrame's index as a column in the SQL table\n",
    "#   We set index=False because:\n",
    "#   1. The Titanic dataset already has meaningful columns\n",
    "#   2. The auto-generated pandas index isn't meaningful for our analysis\n",
    "#   3. Avoiding an extra column keeps the schema cleaner\n",
    "# to_sql() returns None\n",
    "# The data is stored in-memory only since we're using 'sqlite:///:memory:'\n",
    "# To persist to disk, we would need to specify a file path like:\n",
    "#   'sqlite:///titanic.db'\n",
    "\n",
    "titanic_df.to_sql(\"titanic\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the tools available to the ReAct agent\n",
    "\n",
    "- Ensure the agent can query the dataset using SQL commands.\n",
    "- Test the agent's ability to summarize the dataset.\n",
    "- Verify the agent can calculate statistics like mean, median, and mode.\n",
    "- Check if the agent can handle missing data gracefully.\n",
    "\n",
    "### Example questions to ask:\n",
    "\n",
    "- \"How many passengers survived the Titanic disaster?\"\n",
    "- \"What is the average age of the passengers?\"\n",
    "- \"What is the survival rate for male and female passengers?\"\n",
    "- \"Show the top 5 oldest passengers and their survival status.\"\n",
    "- Experiment with filtering data based specific conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced\n",
    "\n",
    "- Use a better prompt, check https://python.langchain.com/docs/integrations/tools/sql_database/#use-within-an-agent\n",
    "- Implement https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html\n",
    "- Use https://docs.chainlit.io/api-reference/elements/plotly to really show visual elements\n",
    "\n",
    "  ```python\n",
    "    show_bar_chart_column = None\n",
    "\n",
    "\n",
    "    @tool\n",
    "    def show_bar_chart(column: str):\n",
    "        \"\"\"Show a bar chart over the specified column.\"\"\"\n",
    "        global show_bar_chart_column\n",
    "\n",
    "    ...\n",
    "\n",
    "    @cl.on_message\n",
    "    async def on_message(message: cl.Message):\n",
    "        ...\n",
    "        global show_bar_chart_column\n",
    "        if show_bar_chart_column is not None:\n",
    "            ...\n",
    "\n",
    "  ```\n",
    "\n",
    "- Split up functionality to use an MCP server (the chainlit app acts as a client) - https://github.com/langchain-ai/langchain-mcp-adapters\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
